# ğŸ§  Omni AI - Advanced Neurosymbolic AI System

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub Stars](https://img.shields.io/github/stars/pratyaypaul6187-art/omni-ai.svg)](https://github.com/pratyaypaul6187-art/omni-ai/stargazers)

> **A sophisticated neurosymbolic AI system with enhanced memory, multimodal processing, and Hollywood-style interface**

ğŸ¬ **NOW WITH CINEMATIC GUI INTERFACE** â€¢ ğŸ§  **ENHANCED AI CONSCIOUSNESS** â€¢ ğŸ”’ **SECURITY FORTRESS**

## âœ¨ Features

- ğŸ§  **Enhanced AI Consciousness** with memory integration and multiple thinking modes
- ğŸ­ **6 Thinking Modes** - Creative, Logical, Analytical, Reflective, Collaborative, Intuitive
- ğŸ“š **Neurosymbolic Reasoning** with knowledge graphs and symbolic logic
- ğŸ¬ **Hollywood-Style GUI** with cinematic interface and fortress control theme
- ğŸ”’ **Security Fortress** with advanced protection and monitoring systems
- ğŸ’¾ **8-Type Memory System** with million-token contexts and intelligent compression
- ğŸŒ **Multimodal Processing** supporting text, image, audio, video, sensor, and temporal data
- ğŸ¢ **Scalable Architecture** designed for billions of parameters and distributed processing
- ğŸ§ª **Comprehensive Testing** with extensive test suites and performance validation

## ğŸš€ Quick Start

### Requirements
- Python 3.9+
- Windows 10/11, macOS, or Linux
- 4GB+ RAM recommended

### Installation

```bash
# Clone the repository
git clone https://github.com/pratyaypaul6187-art/omni-ai.git
cd omni-ai

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Optional: Install GUI dependencies
pip install customtkinter
```

### ğŸ¬ Launch Options

```bash
# Launch the Hollywood-style GUI
python launch_gui.py

# Run simple natural language demo
python simple_nl_demo.py

# Full integration demo
python demo_integration.py

# Advanced reasoning demo
python demo_advanced_reasoning.py
```

## ğŸ’» Usage Examples

### 1. Enhanced AI Consciousness

```python
from src.omni_ai.brain import create_enhanced_consciousness, EnhancedThinkingMode

# Initialize the AI brain
consciousness = await create_enhanced_consciousness(
    memory_db_path="data/my_memory.db",
    enable_neurosymbolic=True
)

# Use different thinking modes
response = await consciousness.enhanced_think(
    "Create a story about robots",
    thinking_mode=EnhancedThinkingMode.CREATIVE
)

print(response['content'])
```

### 2. Natural Language Interface

```python
from src.omni_ai.neurosymbolic.nl_interface import NaturalLanguageInterface

# Quick setup
interface = NaturalLanguageInterface()

# Ask questions
response = await interface.process_query("What is artificial intelligence?")
print(f"Answer: {response.answer}")
print(f"Confidence: {response.confidence}")
```

### 3. Memory System

```python
from src.omni_ai.memory.enhanced_memory import EnhancedMemorySystem

# Create memory system
memory = EnhancedMemorySystem("data/memory.db")

# Store memories
await memory.store_memory(
    content="Paris is the capital of France",
    memory_type="semantic",
    importance=0.8
)

# Search memories
results = await memory.search_memories(
    query="capital of France",
    top_k=5
)
```

### 4. Knowledge Management

```python
from src.omni_ai.neurosymbolic.knowledge_manager import KnowledgeManager

# Create knowledge base
km = KnowledgeManager("demo_knowledge_bases")

# Add facts
kb = await km.create_knowledge_base("Science Facts")
await kb.add_fact("Earth", "orbits", "Sun")
await kb.add_fact("Sun", "is_type", "Star")

# Query knowledge
results = await kb.query("What does Earth orbit?")
```

## ğŸ­ Thinking Modes

Omni AI supports multiple thinking modes for different types of reasoning:

- ğŸ§® **LOGICAL** - Symbolic reasoning and logical deduction
- ğŸ¨ **CREATIVE** - Creative thinking and storytelling  
- ğŸ”¬ **ANALYTICAL** - Deep analysis and problem-solving
- ğŸª **REFLECTIVE** - Self-reflection and introspection
- ğŸ¤ **COLLABORATIVE** - Multi-perspective reasoning
- ğŸ’¡ **INTUITIVE** - Pattern-based intuitive responses
- âš¡ **ADAPTIVE** - Automatically selects best mode

## ğŸ“š Memory Types

The system uses 8 hierarchical memory types:

1. **Sensory** - Ultra-short term sensory input (milliseconds)
2. **Short-term** - Working memory for active processing (minutes)
3. **Long-term** - Persistent long-term storage (permanent)
4. **Episodic** - Event-based memory with context
5. **Semantic** - Factual knowledge and concepts
6. **Procedural** - Skills and procedures
7. **Autobiographical** - Personal history and experiences
8. **Contextual** - Context-dependent memory

## ğŸŒ Multimodal Capabilities

Supported modalities:
- ğŸ“ **Text** - Natural language processing
- ğŸ–¼ï¸ **Image** - Computer vision and image analysis
- ğŸ”Š **Audio** - Speech and audio processing
- ğŸ¥ **Video** - Video content analysis
- ğŸ“¡ **Sensor** - IoT and sensor data
- ğŸ“‹ **Structured** - Databases and structured data
- â° **Temporal** - Time-series data

## ğŸ“ Project Structure

```
omni-ai/
â”œâ”€â”€ ğŸ§  src/omni_ai/
â”‚   â”œâ”€â”€ brain/              # AI consciousness and reasoning
â”‚   â”œâ”€â”€ memory/             # Enhanced memory system
â”‚   â”œâ”€â”€ neurosymbolic/      # Symbolic reasoning & knowledge
â”‚   â”œâ”€â”€ multimodal/         # Multi-modal processing
â”‚   â”œâ”€â”€ security/           # Security and protection
â”‚   â””â”€â”€ core/               # Scalable architecture
â”œâ”€â”€ ğŸ¬ gui/                 # Cinematic interface
â”œâ”€â”€ ğŸ“Š data/                # Memory databases
â”œâ”€â”€ ğŸ§ª tests/               # Test suites
â”œâ”€â”€ ğŸ“š docs/                # Documentation
â””â”€â”€ ğŸ¯ demos/               # Example scripts
```

## ğŸ¬ Hollywood-Style GUI

Launch the cinematic interface:

```bash
python launch_gui.py
```

**GUI Features:**
- ğŸ­ Animated holographic displays
- ğŸ° Fortress control center theme
- ğŸ“Š Real-time system monitoring
- ğŸ¤– Interactive AI chat
- ğŸ”’ Security status dashboard
- ğŸŒŒ Particle effects and animations

## ğŸ›¡ï¸ Safety & Ethics

Omni AI is designed with safety and ethics as core principles:

### âœ… Supported Use Cases
- Text analysis and processing for research and education
- Content organization and cleanup
- Document formatting and extraction
- Writing assistance and readability improvement
- Batch file processing for productivity

### âŒ Explicitly Prohibited
- Harmful content generation
- Privacy violations or unauthorized data access
- Malicious code creation or security exploits
- Any illegal or unethical activities

## ğŸ§ª Development

### Running Tests

```bash
# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# Run tests with coverage
pytest tests/ --cov=omni_ai --cov-report=term-missing

# Run specific test file
pytest tests/test_text_analysis.py -v
```

### Code Quality

```bash
# Format code
black src/ tests/

# Sort imports
isort src/ tests/

# Type checking
mypy src/
```

### Project Structure

```
omni-ai/
â”œâ”€â”€ src/omni_ai/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py              # CLI interface
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ text_analysis.py    # Text analysis functions
â”‚       â”œâ”€â”€ file_utils.py       # File processing utilities
â”‚       â””â”€â”€ safe_processing.py  # Batch processing functions
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_cli.py
â”‚   â””â”€â”€ test_text_analysis.py
â”œâ”€â”€ pyproject.toml          # Project configuration
â””â”€â”€ README.md
```

## ğŸ“Š Examples

### Text Analysis Output

```
$ omni-ai analyze-text --file example.txt

          ğŸ“Š Text Statistics           
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Metric                      â”ƒ Value â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ Word Count                  â”‚ 138   â”‚
â”‚ Character Count             â”‚ 912   â”‚
â”‚ Sentence Count              â”‚ 15    â”‚
â”‚ Avg Words per Sentence      â”‚ 9.2   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

                     ğŸ“– Readability Analysis                      
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Metric               â”ƒ Score â”ƒ Interpretation                  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Flesch Reading Ease  â”‚ 45.2  â”‚ Difficult (College level)       â”‚
â”‚ Flesch-Kincaid Grade â”‚ 12.1  â”‚ Grade 12 level                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤ Contributing

We welcome contributions that align with our safety-first approach!

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes
4. Add tests for new functionality
5. Run tests: `pytest tests/`
6. Submit a pull request

**All contributions must:**
- Adhere to the safety and ethical guidelines
- Include appropriate tests
- Follow the existing code style
- Not introduce any harmful capabilities

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [Typer](https://typer.tiangolo.com/) for the CLI framework
- [Rich](https://rich.readthedocs.io/) for beautiful terminal output
- [TextStat](https://github.com/textstat/textstat) for readability analysis
- Tested with [Pytest](https://pytest.org/)

---

**ğŸ›¡ï¸ Remember: Omni AI is committed to safe, ethical AI practices. Let's build technology that helps, not harms.**
